<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="The lens blur field is a neural representation for modelling optical blur.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning Lens Blur Fields</title>
  
  <!-- Font & CSS -->
  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500&display=swap" rel="stylesheet">

  <!-- Icons -->
  <!-- Font Awesome (no integrity attr to avoid SRI mismatch) -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="style.css">

  <!-- Favicon for browser tab -->
  <link rel="icon" href="./static/images/psf.ico">
</head>
<body>
  <header class="site-header">
    <h1>Learning Lens Blur Fields</h1>
    <p class="authors">
      <a href="https://estherlin.github.io/">Esther Y. H. Lin</a><sup class="aff">1</sup>,
      <a href="https://www.dgp.toronto.edu/~zhecheng/">Zhecheng Wang</a><sup class="aff">1</sup>,
      <a href="https://rebeccayelin.github.io/">Rebecca Lin</a><sup class="aff">2</sup>,
      <a href="https://www.cs.columbia.edu/~dmiau/">Daniel Miau</a><sup class="aff">3</sup>,
      <a href="#">Florian Kainz</a><sup class="aff">3</sup>,
      <a href="https://people.csail.mit.edu/jiawen/">Jiawen Chen</a><sup class="aff">3</sup>,
      <a href="https://ceciliavision.github.io/">Xuaner (Cecilia) Zhang</a><sup class="aff">3</sup>,
      <a href="https://davidlindell.com/">David B. Lindell</a><sup class="aff">1</sup>,
      <a href="http://www.cs.toronto.edu/~kyros/">Kiriakos N. Kutulakos</a><sup class="aff">1</sup>
    </p>
    <p class="institutions">
      <sup>1</sup>University of Toronto &nbsp;&nbsp;·&nbsp;&nbsp;
      <sup>2</sup>Massachusetts Institute of Technology &nbsp;&nbsp;·&nbsp;&nbsp;
      <sup>3</sup>Adobe Inc.
    </p>

    <h3 class="date">TPAMI 2025</h3>

    <nav class="links">
      <a href="https://arxiv.org/abs/2310.11535" class="btn">
        <span class="icon"><i class="ai ai-arxiv"></i></span> arXiv
      </a>
      <a href="https://www.computer.org/csdl/journal/tp/5555/01/11040133/27E7tvof9Ru" class="btn">
        <span class="icon"><i class="fa-solid fa-file"></i></span> TPAMI
      </a>
      <a href="https://github.com/estherlin/learning-lens-blur-fields" class="btn">
        <span class="icon"><i class="fa-brands fa-github"></i></span> Code (soon)
      </a>
      <!-- <a href="https://github.com/estherlin/learning-lens-blur-fields" class="btn disabled">
        <span class="icon"><i class="fa-solid fa-face-smiling-hands"></i></span> Models (soon)
      </a> -->
      <a href="#" class="btn disabled">
        <span class="icon"><i class="fa-solid fa-database"></i></span> Data (soon)
      </a>
    </nav>
  </header>

  <main>
    <!-- Teaser Figure -->
    <div class="teaser-figure">
      <img src="./static/images/teaser.png" alt="Teaser figure">
    </div>

    <section class="abstract">
      <h2>Abstract</h2>
      <p>
        Optical blur is an inherent property of any lens system and is challenging to model in modern cameras because of their complex optical elements. To tackle this challenge, we introduce a high‑dimensional neural representation of blur—<em>the lens blur field</em>—and a practical method for acquisition.
      </p>
      <p>
        The lens blur field is a multilayer perceptron (MLP) designed to (1) accurately capture variations of the lens 2‑D point spread function over image‑plane location, focus setting, and optionally depth; and (2) represent these variations parametrically as a single, sensor‑specific function. The representation models the combined effects of defocus, diffraction, aberration, and accounts for sensor features such as pixel color filters and pixel‑specific micro‑lenses.
      </p>
      <p>
        We provide a first‑of‑its‑kind dataset of 5‑D blur fields—for smartphone cameras, camera bodies equipped with a variety of lenses, <em>etc.</em> Finally, we show that acquired 5‑D blur fields are expressive and accurate enough to reveal, for the first time, differences in optical behavior of smartphone devices of the same make and model.
      </p>
    </section>

    <section class="paper">
      <h2>Overview</h2>
      <p>
        Optical blur, or point spread function (PSF) is an umbrella term for a laundry list of degrading effects such as defocus, diffraction, and aberrations. 
        It's hard to calibrate because it varies with sensor position, focus, target distance, and where you look on the image plane. 
        We introduce **Lens Blur Fields**—tiny MLPs that can model this high-dimensional PSF.
      </p>
      <div class="figure">
        <img src="./static/x/tweet1.png" alt="experimental setup">
      </div>

      <p>Our capture setup only needs a monitor + a simple phone/camera stand. The pipeline is light:</p>

      <ol>
        <li>Capture focal stacks of monitor patterns (in just minutes!)</li>
        <li>Solve a non-blind deconvolution to train the MLP</li>
        <li>Get a continuous, device-specific PSF model</li>
      </ol>

      <div class="figure">
        <img src="./static/x/tweet2.png" alt="pipeline">
      </div>

      <h2>Applications</h2>
      <p>Every lens leaves a blur signature—a hidden fingerprint in every photo. A Lens blur field captures this device-specifc blur. It can be used to tell apart "identical" phones by their optics, deblur images, and render realistic blurs.</p>
      <div class="figure">
        <img src="./static/x/tweet0.png" alt="applications">
      </div>

      <p>Two smartphones of the same make can have subtly different PSFs—your phone has its own blur signature. We show this with the lens blur fields of two iPhone 12 Pros:</p>
      <div class="figure">
        <img src="./static/x/tweet3.png" alt="two iphones">
      </div>

      <p>Lens blur fields let you render device-specific depth-of-field, blur a resolution chart or a 3D scene.</p>
      <div class="figure">
        <img src="./static/x/tweet4.png" alt="rendering">
      </div>

      <p>And with more realistic renders, we can also do better device-specific image restoration.</p>
      <div class="figure">
        <img src="./static/x/tweet5.png" alt="deblurring">
      </div>

      <h2>Dataset</h2>
      <p>We'll be releasing the first dataset of 5D and 6D lens blur fields for smartphone & SLR lenses, plus captures used for training. Stay tuned!</p>
      <div class="figure">
        <img src="./static/x/tweet6.png" alt="dataset">
      </div>

    </section>



    <section class="bibtex">
      <h2>BibTeX</h2>
      <pre><code>@article{lin2025learning,
        title={Learning Lens Blur Fields},
        ISSN={1939-3539},
        url={http://dx.doi.org/10.1109/TPAMI.2025.3578587},
        DOI={10.1109/tpami.2025.3578587},
        journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
        publisher={Institute of Electrical and Electronics Engineers (IEEE)},
        author={Lin, Esther Y. H. and Wang, Zhecheng and Lin, Rebecca and Miau, Daniel and Kainz, Florian and Chen, Jiawen and Zhang, Xuaner and Lindell, David B. and Kutulakos, Kiriakos N.},
        year={2025},
        pages={1–12}}</code></pre>
    </section>
  </main>

  <footer>
    <p>Updated July 2025</p>
  </footer>
</body>
</html>